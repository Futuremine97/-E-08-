{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a91bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b161afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "086ea980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29162dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47013</th>\n",
       "      <td>Former Gitanjali Gems Managing Director Santos...</td>\n",
       "      <td>Choksi threatened to trap me in fraud case: Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47937</th>\n",
       "      <td>Praising the Centre's progress in installing C...</td>\n",
       "      <td>CCTVs in courtrooms not meant for recording pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>Facebook-owned virtual reality headset maker O...</td>\n",
       "      <td>I am moving on: Oculus Co-founder to leave Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45603</th>\n",
       "      <td>The CBI has charged former CMD of United Bank ...</td>\n",
       "      <td>Ex-CMD of United Bank of India charged for Ã¢Â...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>Praising the Indian cricket team's bowling coa...</td>\n",
       "      <td>Full marks to Bharat Arun: Shastri praises bow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45827</th>\n",
       "      <td>The mascots for the Tokyo 2020 Olympics and Pa...</td>\n",
       "      <td>Mascot chosen by children for Tokyo 2020 Olymp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11009</th>\n",
       "      <td>A nine-year-old Bakarwal girl died and three o...</td>\n",
       "      <td>9-yr-old girl dies in landslide in J&amp;K, 700 pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72979</th>\n",
       "      <td>Bengaluru Metro has announced that its first c...</td>\n",
       "      <td>Bengaluru Metro to have its first creche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91758</th>\n",
       "      <td>The Donald Trump administration has summoned a...</td>\n",
       "      <td>Trump summons full Senate to N Korea briefing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81601</th>\n",
       "      <td>Pakistan has executed as many as 465 prisoners...</td>\n",
       "      <td>Pakistan conducts fifth-most executions in wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>Gold-winner Manjit Singh and silver-winner Jin...</td>\n",
       "      <td>Only 3rd time in Asiad India has won 2 medals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>Team India captain Virat Kohli danced to 'Mere...</td>\n",
       "      <td>Kohli dances to 'Mere Desh Ki Dharti' with fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82125</th>\n",
       "      <td>Australian tennis player Bernard Tomic faked i...</td>\n",
       "      <td>Player takes time-out in Wimbledon match after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31906</th>\n",
       "      <td>Chennai Super Kings off-spinner Harbhajan Sing...</td>\n",
       "      <td>No one can beat Yuvraj when it comes to fartin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>A 47-year-old owner of Mumbai paying guest hou...</td>\n",
       "      <td>Mumbai hostel owner films girls with hidden ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "47013  Former Gitanjali Gems Managing Director Santos...   \n",
       "47937  Praising the Centre's progress in installing C...   \n",
       "12502  Facebook-owned virtual reality headset maker O...   \n",
       "45603  The CBI has charged former CMD of United Bank ...   \n",
       "4028   Praising the Indian cricket team's bowling coa...   \n",
       "45827  The mascots for the Tokyo 2020 Olympics and Pa...   \n",
       "11009  A nine-year-old Bakarwal girl died and three o...   \n",
       "72979  Bengaluru Metro has announced that its first c...   \n",
       "91758  The Donald Trump administration has summoned a...   \n",
       "81601  Pakistan has executed as many as 465 prisoners...   \n",
       "19732  Gold-winner Manjit Singh and silver-winner Jin...   \n",
       "3078   Team India captain Virat Kohli danced to 'Mere...   \n",
       "82125  Australian tennis player Bernard Tomic faked i...   \n",
       "31906  Chennai Super Kings off-spinner Harbhajan Sing...   \n",
       "4714   A 47-year-old owner of Mumbai paying guest hou...   \n",
       "\n",
       "                                               headlines  \n",
       "47013  Choksi threatened to trap me in fraud case: Ex...  \n",
       "47937  CCTVs in courtrooms not meant for recording pr...  \n",
       "12502  I am moving on: Oculus Co-founder to leave Fac...  \n",
       "45603  Ex-CMD of United Bank of India charged for Ã¢Â...  \n",
       "4028   Full marks to Bharat Arun: Shastri praises bow...  \n",
       "45827  Mascot chosen by children for Tokyo 2020 Olymp...  \n",
       "11009  9-yr-old girl dies in landslide in J&K, 700 pe...  \n",
       "72979           Bengaluru Metro to have its first creche  \n",
       "91758  Trump summons full Senate to N Korea briefing ...  \n",
       "81601  Pakistan conducts fifth-most executions in wor...  \n",
       "19732  Only 3rd time in Asiad India has won 2 medals ...  \n",
       "3078   Kohli dances to 'Mere Desh Ki Dharti' with fan...  \n",
       "82125  Player takes time-out in Wimbledon match after...  \n",
       "31906  No one can beat Yuvraj when it comes to fartin...  \n",
       "4714   Mumbai hostel owner films girls with hidden ca...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text','headlines']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1437456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c6e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "500bb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text         0\n",
      "headlines    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6e6efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f58c5c",
   "metadata": {},
   "source": [
    "# 행 단위로 null 값을 대치함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc472bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea29f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d56cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e165737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59934a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a49e9915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37fff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878d206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "headlines    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7bcd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83347373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcTElEQVR4nO3df3RV5Z3v8fcnEYNYKlIyDBVpXPVXGu6oNbe1V6YWRbGdLvEPbGVaF9WMrOhMbufKvUbN6rWuW1hlZuyPy8wiFwcK0zpRx/6A6+pUBKIuvK3T0KoDxKp1SotViBXUolIM3/vH2diTNCEnv87e55zPa62zcvZz9sn5Ijx+zrP3s5+tiMDMzCxrqtIuwMzMbCAOKDMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgSoCk3+Y9jkh6M2/7MyP4fR+TtGc8ajUbT5LmSPp/kl6V9IqkxyT957TrsvFxXNoF2NAi4l1Hn0v6BfAXEbE5vYrMik/Su4EHgBuA+4DjgT8FDqVZ13BIEqCIOJJ2LaXAI6gSJqlK0i2Sfi7pN5LukzQ1eW2VpG/n7btC0hZJJwL/Crw3bxT23rT+DGbDcCZARHRERG9EvBkRmyLiKUlflPStoztKqpMUko5Lth+W9KVk9PVbSf9X0nsk3S3pNUk/llSX9/6QdKOkZyW9Lul/SXp/8v7Xkr52fLLvyZIekNQjaX/yfGbe73pY0jJJjwFvAEslbc//g0m6SdKGcf2vV4IcUKWtBbgSuAh4L7Af+IfktaXAf5L0OUl/CjQBiyPiIPBx4NcR8a7k8evil242bM8AvZLWS/q4pJOH+f6rgWuAU4D3Az8EvgFMBbqB2/vtPx84H7gAuBlYDXwWOBWYDSxK9qtKfs/7gFnAm8Df9/td1wBLgMnA/wZOk1Tf7/V/Guafp+w5oEpbM9AWEXsi4hDwRWChpOMi4g1y/+i/AnwLaIkIn3eykhURrwFzgADuAnokbZQ0vcBf8Y2I+HlEvEruKMLPI2JzRLwN/AtwXr/9/yYiXouIncAOYFNEPJ/3/vOSun4TEd+OiDci4nVgGbkvjfnWRcTOiHg76av3kgs7JDUAdeQOX1oeB1Rpex/wXUkHJB0g9y2wF5gOEBGPA88DInfM3qykRUR3RHwuImaSG8W8F/hagW/fm/f8zQG239V398L2lzRJ0v+RtFvSa8CjwBRJ1Xn7/6rf714P/HlyTuoa4L4kuCyPA6q0/Qr4eERMyXtMjIgXACT9JVAD/JrcIYqjvIS9lbyIeBpYRy6oDgKT8l7+4yKWshQ4C/hwRLwb+GjSrrx9+vS5iPgR8Dtykzz+HPhmEeosOQ6o0tYOLJP0PgBJtZIWJM/PBL5E7jDCNcDNks5N3rcXeI+kk4pfstnISDpb0tKjExAknUruPNCPgCeAj0qalfy7vrWIpU0mN6I6kExS6n8uazD/RO5c1eGI2DZexZUyB1Rp+zqwEdgk6XVyHfXDycylbwErIuLJiHgWuA34pqSa5JtnB/B8cnjQs/isFLwOfBh4XNJBcv/edwBLI+Ihcud1ngK2U9zzOV8DTgBeTmr6QYHv+ya50d+3htqxUsk3LDQzKz5JJwD7gA8mXyKtH4+gzMzScQPwY4fT4LyShJlZkSUrwojcdYw2CB/iMzOzTPIhPjMzy6SiHuKbNm1a1NXVFfMjzcbN9u3bX46I2mJ/rvuRlZvB+lJRA6quro6urq5ifqTZuJG0O43PdT+ycjNYX/IhPjMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJhUUUJKmSLpf0tOSuiV9RNJUSQ9Jejb5OdzbL9sY6+joYPbs2VRXVzN79mw6OjrSLsnySForaZ+kHf3aW5K+tVPS36RVn/3e/PnzqaqqQhJVVVXMnz8/7ZIqUqEjqK8DP4iIs4FzyN259RZgS0ScAWxJti0lHR0dtLW1sXLlSt566y1WrlxJW1ubQypb1gGX5zdImgssAM6JiAbg71Koy/LMnz+fTZs20dzczIEDB2hubmbTpk0OqTRExDEfwEnAf5Cs25fX/jNgRvJ8BvCzoX7X+eefHzY+GhoaYuvWrX3atm7dGg0NDSlVVP6Arhji33z/B1AH7Mjbvg+YN5zf4X40viTFDTfc0KfthhtuCEkpVVT+ButLQy4Wm9yFdTWwi9zoaTvweeCFiJiS7CNg/9Htfu9fAiwBmDVr1vm7d6dy8X3Zq66u5q233mLChAnvtB0+fJiJEyfS29ubYmXlS9L2iGgc5nvqgAciYnay/QSwgdzI6i3gv0fEjwd4n/tRkUjiwIEDnHTS7284/eqrrzJlyhSG+v+ljcxgfamQQ3zHAR8EVkXEecBB+h3OSxJwwL+5iFgdEY0R0VhbW/RlyypGfX0927b1vWv0tm3bqK+vT6kiK9BxwFTgAuB/APclX/j6cD8qHkncemvfO8bfeuutDPDXYuOskIDaA+yJiMeT7fvJBdZeSTMAkp/7xqdEK0RbWxtNTU10dnZy+PBhOjs7aWpqoq2tLe3S7Nj2AN9JjnT8G3AEmJZyTRXt0ksvZdWqVdx44428+uqr3HjjjaxatYpLL7007dIqzpCLxUbES5J+JemsiPgZcAm5w327gMXAl5OfG8a1UjumRYsWAdDS0kJ3dzf19fUsW7bsnXbLrO8Bc4FOSWcCxwMvp1pRhXvwwQeZP38+7e3trFq1CklcdtllPPjgg2mXVnEKXc28Bbhb0vHA88C15EZf90lqAnYDnxqfEq1QixYtciBlmKQO4GPANEl7gNuBtcDaZOr574DF4RMdqXMYZUNBARURTwADnQy+ZEyrMStjETHYt4fPFrUQsxLhlSTMzCyTHFBmZpZJDigzM8skB5SZmWWSA8rMzDKp0GnmZmYVY6BVIzz7v/g8gjIzy5MfTvfcc8+A7VYcDigzswFEBJ/+9Kc9ckqRA8rMrJ/8kdNA21YcDqgy4jvqmo2Nq6+++pjbVhwOqDLhO+qajS1J3HvvvT73lCIHVJlYtmwZa9asYe7cuUyYMIG5c+eyZs0ali1blnZpZiUl/5xT/sjJ56KKz9PMy0R3dzdz5szp0zZnzhy6u7tTqsisdDmMssEjqDJRX1/PHXfc0ecc1B133OE76ppZyXJAlYm5c+eyYsUKrrvuOl5//XWuu+46VqxYwdy5c9MuzcxsRBxQZaKzs5PW1lbWrl3L5MmTWbt2La2trXR2dqZdmpnZiPgcVJno7u5mxowZ7Nq1i4hg165dzJgxw+egzKxkeQRVJk444QQ2b95Mc3MzBw4coLm5mc2bN3PCCSekXZqZ2Yg4oMrEwYMHmTx5MldddRWTJk3iqquuYvLkyRw8eDDt0szMRsQBVUbuvPNOWlpamDhxIi0tLdx5551pl2R5JK2VtE/SjgFeWyopJE1LozbrS9IfPKz4HFBlQhKtra3s3LmTI0eOsHPnTlpbW92xsmUdcHn/RkmnApcBvyx2QfaHBusz7kvF54AqE5MmTWL//v3U1dXx3HPPUVdXx/79+5k0aVLapVkiIh4FXhngpa8CNwO+OjRDIuKdh6XDs/jKxMGDB5k2bRq7d+/m9NNPRxLTpk3j5ZdfTrs0OwZJC4AXIuLJY31Dl7QEWAIwa9asIlVnli6PoMpIbW3tO9/2IoLa2tqUK7JjkTQJuA34n0PtGxGrI6IxIhr992qVwgFVRrq7u7niiivo6enhiiuu8DVQ2fd+4DTgSUm/AGYCP5H0x6lWZQCeIJEBPsRnlpKI+Hfgj45uJyHVGBE+LpuiiBgwlHwuqvgcUGXk7LPPZuPGje8c2jv77LN5+umnU67KjpLUAXwMmCZpD3B7RKxJtyobiMMoGwoKqOSb3etAL/B2RDRKmgrcC9QBvwA+FRH7x6dMK0T/MHI4ZUtELBri9boilWJWEoZzDmpuRJwbEY3J9i3Alog4A9iSbFsG3H///WmXYGY2aqOZJLEAWJ88Xw9cOepqbEwsXLgw7RLMzEat0IAKYJOk7cn1GADTI+LF5PlLwPSB3ihpiaQuSV09PT2jLNeOZfPmzX0uLty8eXPaJZmZjVihkyTmRMQLkv4IeEhSn5MbERGSBjyrGBGrgdUAjY2NPvM4jubNm5d2CWZmY6agEVREvJD83Ad8F/gQsFfSDIDk577xKtKGZ8WKFWmXYGY2akMGlKQTJU0++pzcopY7gI3A4mS3xcCG8SrShqe1tTXtEszMRq2QQ3zTge8mF64dB/xzRPxA0o+B+yQ1AbuBT41fmWZmVmmGHEFFxPMRcU7yaIiIZUn7byLikog4IyLmRcRAqzRbCr7whS+kXYKZ2ah5Lb4yU1VVxUUXXURVlf9qzQox0M0JC3nY+PNSR2XmyJEjns1nNgzHWtZIkpc9SpG/ZpuZWSY5oMzMLJMcUGZmlkkOKDMzyyQHlJmZZZIDqgxNnz7gur1mZiXFAVWG9u7dm3YJZmaj5uugykz+NRu+mNDMSpkDqsw4lMysXPgQX5kY7Gp3XwWfHZLWStonaUde299KelrSU5K+K2lKiiWaZYoDqkQVujaY1xDLlHXA5f3aHgJmR8SfAM8Atxa7KLOsckCVqPxbu/d/FPK6FV9EPAq80q9tU0S8nWz+CJhZ9MLMMsoBZZYd1wH/mnYRZlnhgDLLAEltwNvA3YO8vkRSl6Sunp6e4hZnlhIHlFnKJH0O+CTwmRjkGGxErI6IxohorK2tLWp9ZmnxNHOzFEm6HLgZuCgi3ki7HrMs8QjKrEgkdQA/BM6StEdSE/D3wGTgIUlPSGpPtUizDPEIyqxIImLRAM1ril6IWYnwCMrMzDLJAWVmZpnkgDIzs0xyQJmZWSY5oMzMLJMcUGZmlkkOKDMzy6SCA0pStaSfSnog2T5N0uOSnpN0r6Tjx69MMzOrNMMZQX0e6M7bXgF8NSJOB/YDTWNZmJmZVbaCAkrSTODPgH9MtgVcDNyf7LIeuHIc6jMzswpV6Ajqa+QWtDySbL8HOJB3o7U9wCkDvdG3CTAzs5EYMqAkfRLYFxHbR/IBvk2AmZmNRCGLxV4IXCHpE8BE4N3A14Epko5LRlEzgRfGr0wzM6s0Q46gIuLWiJgZEXXA1cDWiPgM0AksTHZbDGwYtyrNzKzijOY6qFbgJknPkTsn5dsGmJnZmBnW/aAi4mHg4eT588CHxr4kMzMzryRhZmYZ5YDKsKlTpyJp2A9g2O+ZOnVqyn9aM7O+fMv3DNu/fz8RUZTPOhpsZmZZ4RGUmZllkgPKrEgkrZW0T9KOvLapkh6S9Gzy8+Q0azTLEgeUWfGsAy7v13YLsCUizgC2JNtmhgPKrGgi4lHglX7NC8gttgxedNmsDweUWbqmR8SLyfOXgOkD7eRFl0fHM2JLk2fxmWVERISkAadtRsRqYDVAY2NjcaZ2lhHPiC1NHkGZpWuvpBkAyc99KddjlhkOKLN0bSS32DJ40WWzPhxQZkUiqQP4IXCWpD2SmoAvA5dKehaYl2ybGT4HlWlx+7vhiycV77NsXEXEokFeuqSohZiVCAdUhumO14p6Yje+WJSPMjMriA/xmZlZJjmgzMwskxxQZmaWSQ4oMzPLJAeUmZllkmfxZVyxlk05+WTf5cHMssUBlWEjnWIuqWjT083MxosDyszKni96L00OKDMre77ovTR5koSZmWWSA8rMzDLJAWVmZpnkgDIzs0waMqAkTZT0b5KelLRT0h1J+2mSHpf0nKR7JR0//uWamVmlKGQEdQi4OCLOAc4FLpd0AbAC+GpEnA7sB5rGrUozM6s4QwZU5Pw22ZyQPAK4GLg/aV8PXDkeBZqZWWUq6ByUpGpJTwD7gIeAnwMHIuLtZJc9wCmDvHeJpC5JXT09PWNQspmZVYKCAioieiPiXGAm8CHg7EI/ICJWR0RjRDTW1taOrEozM6s4w5rFFxEHgE7gI8AUSUdXopgJvDC2pZlVDkn/LZmEtENSh6SJaddklrZCZvHVSpqSPD8BuBToJhdUC5PdFgMbxqlGs7Im6RTgvwKNETEbqAauTrcqs/QVshbfDGC9pGpygXZfRDwgaRdwj6QvAT8F1oxjnWbl7jjgBEmHgUnAr1Ouxyx1QwZURDwFnDdA+/PkzkeZ2ShExAuS/g74JfAmsCkiNuXvI2kJsARg1qxZxS+yDPjeaqXHK0mYpUzSycAC4DTgvcCJkj6bv48nG41ORIzoMZL3vvLKKyn/acuHA8osffOA/4iInog4DHwH+C8p12SWOgeUWfp+CVwgaZJyx6EuITcRyayiOaDMUhYRj5NbleUnwL+T65erUy3KLAN8R12zDIiI24Hb067DLEs8gjIzs0xyQJmZWSY5oMzMLJN8DqpEDXXR4bFeP3p9h5lZljmgStRAITNQKDmMzKxU+RBfmRhsxFSs5V3MzMaaR1BlJn/E5HAys1LmgCozDiUzKxc+xGdmZpnkgDIzs0xyQJmZWSY5oMzMLJMcUGZmlkkOKDMzyyQHVBlZsGBBn1tPL1iwIO2SzMxGzNdBlZENGzb4OigzKxseQZWhc845J+0SzMxGzQFVhp588sm0SzAzGzUHlJmZZZIDqsxUV1fz8MMPU11dnXYpNgySpki6X9LTkrolfSTtmszS5kkSZaa3t5eXX36Z3t7etEux4fk68IOIWCjpeGBS2gWZpc0BVYYWLlyYdgk2DJJOAj4KfA4gIn4H/C7NmsyyYMhDfJJOldQpaZeknZI+n7RPlfSQpGeTnyePf7lmZek0oAf4hqSfSvpHSSfm7yBpiaQuSV09PT3pVGlWZIWcg3obWBoRHwAuAP5S0geAW4AtEXEGsCXZtgz43ve+l3YJNjzHAR8EVkXEecBB+vWniFgdEY0R0VhbW5tGjWZFN2RARcSLEfGT5PnrQDdwCrAAWJ/sth64cpxqtGG68sor0y7BhmcPsCciHk+27ycXWGYVbViz+CTVAecBjwPTI+LF5KWXgOmDvMeHJork2muvpaamBoCamhquvfbalCuyQkTES8CvJJ2VNF0C7EqxJLNMKDigJL0L+Dbw1xHxWv5rERFADPQ+H5oonnXr1rF8+XIOHjzI8uXLWbduXdolWeFagLslPQWcCyxPtxyz9BUUUJImkAunuyPiO0nzXkkzktdnAPvGp0QrhCQigkceeYQ33niDRx55hIjw2nwlIiKeSL7I/UlEXBkR+9OuySxthcziE7AG6I6Ir+S9tBFYnDxfDGwY+/KsUBFBQ0MDGzdupLa2lo0bN9LQ0EBucGtmVnoKGUFdCFwDXCzpieTxCeDLwKWSngXmJduWkpqaGqZMmdLnHFT+tplZqSlkFt+2iFBy6OHc5PH9iPhNRFwSEWdExLyIeKUYBdvAzjzzTB577DHmz59PT08P8+fP57HHHuPMM89MuzQzsxHxShJl4plnnuHCCy/kwQcfpLa2lpqaGi688EK6urrSLs3MbEQcUGXi0KFDbNq0iUmTfr+E2xtvvMGJJ554jHeZmWWXVzMvEzU1NbS3t/dpa29v9zkoMytZHkGVieuvv57W1lYAmpubaW9vp7W1lebm5pQrMzMbGQdUmVi5ciUAt912G0uXLqWmpobm5uZ32s3MSo0DqoysXLnSgWRmZcMBZWYVbajVVgZ73RfBjz8HlJlVNAdNdnkWn5mZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgzMwskxxQZmaWSQ4oMzPLJAeUmZllkgPKLCMkVUv6qaQH0q6l0kn6g4cVnwPKLDs+D3SnXUSlOxpGVVVVbN68maqqqj7tVjxei88sAyTNBP4MWAbclHI5Fa+qqore3l4Aent7qa6u5siRIylXVXk8gjLLhq8BNwMD/l9Q0hJJXZK6enp6ilpYJdq0adMxt604HFBmKZP0SWBfRGwfbJ+IWB0RjRHRWFtbW8TqKtNll112zG0rDgeUWfouBK6Q9AvgHuBiSd9Kt6TKduTIEaqrq9myZYsP76XIAWWWsoi4NSJmRkQdcDWwNSI+m3JZFevo/aGOHDnCvHnz3gkn3zeq+DxJwsysH4dRNjigzDIkIh4GHk65DLNM8CE+MzPLpCEDStJaSfsk7chrmyrpIUnPJj9PHt8yzcys0hQygloHXN6v7RZgS0ScAWxJts3MzMbMkAEVEY8Cr/RrXgCsT56vB64c27LMzKzSjfQc1PSIeDF5/hIwfbAdfQW8mZmNxKgnSURuPuagczJ9BbyZlZqWlhYmTpyIJCZOnEhLS0vaJVWkkQbUXkkzAJKf+8auJDOz9LS0tNDe3s7y5cs5ePAgy5cvp7293SGVgpEG1EZgcfJ8MbBhbMoxM0vXXXfdxYoVK7jpppuYNGkSN910EytWrOCuu+5Ku7SKU8g08w7gh8BZkvZIagK+DFwq6VlgXrJtZlbyDh06RHNzc5+25uZmDh06lFJFlauQWXyLImJGRExI1gtbExG/iYhLIuKMiJgXEf1n+ZmZlaSamhra29v7tLW3t1NTU5NSRZXLSx2ZmeW5/vrraW1tBXIjp/b2dlpbW/9gVGXjzwFlZpZn5cqVANx2220sXbqUmpoampub32m34nFAmZn1s3LlSgdSBnixWDMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgzFIm6VRJnZJ2Sdop6fNp12SWBb4Oyix9bwNLI+InkiYD2yU9FBG70i7MLE0eQZmlLCJejIifJM9fB7qBU9Ktyix9DiizDJFUB5wHPN6v3XemtorjgDLLCEnvAr4N/HVEvJb/mu9MbZXIAWWWAZImkAunuyPiO2nXY5YFDiizlEkSsAbojoivpF2PWVY4oMzSdyFwDXCxpCeSxyfSLsosbZ5mbpayiNgGKO06zLLGIygzM8skB5SZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQJWRjo4OZs+eTXV1NbNnz6ajoyPtksxKkvtSNniaeZno6Oigra2NNWvWMGfOHLZt20ZTUxMAixYtSrk6s9LhvpQhEVG0x/nnnx82PhoaGmLr1q192rZu3RoNDQ0pVVT+gK4oYv8J96OicF8qvsH6knKvFUdjY2N0dXUV7fMqSXV1NW+99RYTJkx4p+3w4cNMnDiR3t7eFCsrX5K2R0RjsT/X/Wh8uS8V32B9aVTnoCRdLulnkp6TdMtofpeNTn19Pdu2bevTtm3bNurr61OqyKw0uS9lx4gDSlI18A/Ax4EPAIskfWCsCrPhaWtro6mpic7OTg4fPkxnZydNTU20tbWlXZpZSXFfyo7RTJL4EPBcRDwPIOkeYAHg21Sn4OjJ25aWFrq7u6mvr2fZsmU+qWs2TO5L2THic1CSFgKXR8RfJNvXAB+OiL/qt98SYAnArFmzzt+9e/foKjbLCJ+DMhsb43IOqhDhO4GamdkIjCagXgBOzduembSZmZmN2mgC6sfAGZJOk3Q8cDWwcWzKMjOzSjfiSRIR8bakvwIeBKqBtRGxc8wqMzOzijaqpY4i4vvA98eoFjMzs3d4sVgzM8ukoi51JKkH8Dzz8TcNeDntIirA+yKi6FNT3Y+Kyn2pOAbsS0UNKCsOSV1pXJ9jVm7cl9LlQ3xmZpZJDigzM8skB1R5Wp12AWZlwn0pRT4HZWZmmeQRlJmZZZIDyszMMskBVUYkrZW0T9KOtGsxK1XuR9nhgCov64DL0y7CrMStw/0oExxQZSQiHgVeSbsOs1LmfpQdDigzM8skB5SZmWWSA8rMzDLJAWVmZpnkgCojkjqAHwJnSdojqSntmsxKjftRdnipIzMzyySPoMzMLJMcUGZmlkkOKDMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTPr/kwPRsVWQTowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62a798",
   "metadata": {},
   "source": [
    "# summary 의 경우 text 의 평균 38 보다 9 정도로 줄어든 것을 확인 가능합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "410fe277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa252e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "946df709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.2755693371289142\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "331c82fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 27105\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f75e7",
   "metadata": {},
   "source": [
    "# 정해진 길이보다 길면 제외 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "499c7ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>union minister dharmendra pradhan wednesday cl...</td>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "      <td>sostoken odisha cm patnaik controls mining maf...</td>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>indian space research organisation wednesday u...</td>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "      <td>sostoken isro unveils bengaluru centre for man...</td>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>least people killed others injured saudi arabi...</td>\n",
       "      <td>killed injured in saudi arabia floods</td>\n",
       "      <td>sostoken killed injured in saudi arabia floods</td>\n",
       "      <td>killed injured in saudi arabia floods eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>investigators searching lost plane carrying ar...</td>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "      <td>sostoken seat cushions from missing plane carr...</td>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agustawestland chopper scam co accused rajiv s...</td>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "      <td>sostoken agustawestland scam accused rajiv sax...</td>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "19  union minister dharmendra pradhan wednesday cl...   \n",
       "21  indian space research organisation wednesday u...   \n",
       "22  least people killed others injured saudi arabi...   \n",
       "29  investigators searching lost plane carrying ar...   \n",
       "36  agustawestland chopper scam co accused rajiv s...   \n",
       "\n",
       "                                            headlines  \\\n",
       "19  odisha cm patnaik controls mining mafia union ...   \n",
       "21  isro unveils bengaluru centre for manned space...   \n",
       "22              killed injured in saudi arabia floods   \n",
       "29  seat cushions from missing plane carrying foot...   \n",
       "36  agustawestland scam accused rajiv saxena extra...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "19  sostoken odisha cm patnaik controls mining maf...   \n",
       "21  sostoken isro unveils bengaluru centre for man...   \n",
       "22     sostoken killed injured in saudi arabia floods   \n",
       "29  sostoken seat cushions from missing plane carr...   \n",
       "36  sostoken agustawestland scam accused rajiv sax...   \n",
       "\n",
       "                                       decoder_target  \n",
       "19  odisha cm patnaik controls mining mafia union ...  \n",
       "21  isro unveils bengaluru centre for manned space...  \n",
       "22     killed injured in saudi arabia floods eostoken  \n",
       "29  seat cushions from missing plane carrying foot...  \n",
       "36  agustawestland scam accused rajiv saxena extra...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "940fffa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c394d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3880   290 17880 ...  2136 20290  8569]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9c78a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61c5845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 5421\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca14ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 21684\n",
      "훈련 레이블의 개수 : 21684\n",
      "테스트 데이터의 개수 : 5421\n",
      "테스트 레이블의 개수 : 5421\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbe3713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3727ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 42494\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 30768\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11726\n",
      "단어 집합에서 희귀 단어의 비율: 72.40551607285735\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 8.295299295334798\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfd082eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70ce72a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1235, 2201, 2171, 35, 106, 28, 970, 136, 142, 81, 452, 2202, 744, 1135, 452, 193, 371, 2327, 63, 33, 1644, 1665, 5792, 758, 1823, 730, 17, 35, 336, 3145, 13, 1061, 4, 1932, 603, 1236], [54, 155, 458, 5081, 1, 763, 233, 1666, 151, 78, 24, 84, 26, 78, 1087, 233, 1666, 1119, 90, 606, 787, 5590, 864, 244, 1075, 1666, 38, 104, 763], [2114, 3607, 489, 2775, 2563, 1566, 1076, 6474, 764, 453, 1088, 52, 1, 44, 47, 2075, 1088, 82, 281, 1566, 374, 5082, 18, 43, 95, 950, 79, 677, 24, 100, 2114, 657, 153, 41, 1566, 1933]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf4e65d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a8ae61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 18935\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 14290\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4645\n",
      "단어 집합에서 희귀 단어의 비율: 75.46870874042779\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 14.145985714592136\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c18a8e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1062, 137, 602, 1452, 19, 28, 48], [1, 36, 428, 273, 1931, 77, 4, 40], [1, 1338, 1339, 4, 1724, 1811, 4, 1533], [1, 274, 719, 105, 4, 941, 39], [1, 203, 1453, 118, 12, 1454]]\n",
      "target\n",
      "decoder  [[1062, 137, 602, 1452, 19, 28, 48, 2], [36, 428, 273, 1931, 77, 4, 40, 2], [1338, 1339, 4, 1724, 1811, 4, 1533, 2], [274, 719, 105, 4, 941, 39, 2], [203, 1453, 118, 12, 1454, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07a29bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 21677\n",
      "훈련 레이블의 개수 : 21677\n",
      "테스트 데이터의 개수 : 5418\n",
      "테스트 레이블의 개수 : 5418\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31199a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81471d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Activation, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "#encoder_inputs = GaussianNoise(stddev=0.08)(encoder_inputs)\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb2 = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "#enc_emb2 = GaussianNoise(stddev=0.1)(enc_emb)\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, activation= 'tanh' ,return_sequences=True, return_state=True ,dropout = 0.38, recurrent_dropout = 0.42)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb2)\n",
    "#state_c1 = GaussianNoise(stddev=0.01)(state_c1)\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, activation= 'tanh', return_sequences=True, return_state=True, dropout=0.38, recurrent_dropout=0.47)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "#state_c2 = GaussianNoise(stddev=0.01)(state_c2)\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, activation= 'tanh', return_state=True, return_sequences=True, dropout=0.38, recurrent_dropout=0.47)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382ee5f",
   "metadata": {},
   "source": [
    "## recurrent_dropout = 0 조건 충족못하면 cuDNN 사용 불가능 오류가 뜬다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb42ce",
   "metadata": {},
   "source": [
    "###### 임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 돼요. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "#### 또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용해요. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법이에요.반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이에요. 즉 time step의 입력을 랜덤으로 생략해 주는 거죠. recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 해요.아래 그림은 일반적인 dropout과, dropout과 recurrent dropout을 동시에 사용한 것을 시각적으로 표현한 것입니다. 색이 있는 화살표는 dropout을 나타낸 것이에요. (색이 다른 것은 다른 dropout mask를 사용했다는 표시인데, 지금은 그냥 넘어가셔도 됩니다.) 우리가 현재 사용한 LSTM은 dropout과 recurrent dropout을 모두 사용했으니 오른쪽 그림과 같은 형태겠군요. 참고로 dropout과 recurrent dropout을 모두 사용한 것을 Variational Dropout이라고도 해요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aea4e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import noise layer\n",
    "from keras.layers import GaussianNoise\n",
    "# 디코더 설계\n",
    "tar_vocab3 = GaussianNoise(stddev=0.09)(tar_vocab)\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab3, embedding_dim)\n",
    "\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "#dec_emb2 = GaussianNoise(stddev=0.09)(dec_emb)\n",
    "# 디코더의 LSTM\n",
    "\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ada7c",
   "metadata": {},
   "source": [
    "### 우리는  return_sequences=True, return_state=True 조건을 명시했으므로 모든 Hidden state 들이 표시되고 마지막 Hidden state, 마지막 Cell state 들이 반환된다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b8038",
   "metadata": {},
   "source": [
    "### return_sequences parameter is True일 경우, decoder_outputs 은 batch 의 샘플수를 의미한다.\n",
    "### 첫 번째 차원 은 LSTM 레이어에 제공된 batch의 샘플 \"수\" 를 나타냅니다.\n",
    "### 두 번째 차원 은 입력 시퀀스 의 시간 단계 수입니다. \n",
    "### 두 번째 차원을 인덱싱 하여 주어진 시간 단계 에서 단위의 모든 hidden state 에 액세스 할 수 있습니다.\n",
    "### 세 번째 차원 은 Keras LSTM 구현에서 units 매개변수에 의해 정의된 \"출력 공간\" 의 차원입니다 .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0ad63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    256000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   514000      lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "# print(tar_vocab.shape)\n",
    "#tar_vocab2 = GaussianNoise(stddev=0.09)(tar_vocab)\n",
    "tar_vocab2 = GaussianNoise(stddev=0.09)(tar_vocab)\n",
    "print(tar_vocab2.shape)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) #위에서 나온 디코더 아웃풋,즉 배치의 샘플수를 softmax layer에 입력으로 넣는다.\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b7051",
   "metadata": {},
   "source": [
    "## Since we have 4 time steps and unit (dimensionality of the output space) is set to 16, the output shape will be (None, 4, 16). None은 모든 배치 사이즈를 뜻하는 자리표시자다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3b41c",
   "metadata": {},
   "source": [
    "### Concatenate(axis=-1)일 경우 가장낮은 차원에서 더해준다. 글자들이므로, 2*1*3을 axis= -1의 연산을 해준다면 2*1*6의 텐서가 될 것이다\n",
    "### 아이스크림 2개가 있다고 쳐보자. 아이스크림(3차원)의 크림부분(2차원)을 분해해서 바닐라(1차원)가 있다면 다른 한개에서 구슬아이스크림을 뺀다음 두개를 합쳐주는 것과 같다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "280461f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    256000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   514000      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 2000)   4002000     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,635,104\n",
      "Trainable params: 7,635,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "\n",
    "#decoder_softmax_outputs = Activation('tanh')(decoder_concat_input) #여기 도전해본 코드가 있습니다. tanh 레이어를 추가시켰습니다.\n",
    "\n",
    "decoder_softmax_outputs2 =decoder_softmax_layer(decoder_softmax_outputs)\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788edc83",
   "metadata": {},
   "source": [
    "## sparse_categorical_crossentropy 는 각 샘플이 오직 하나의 class 에 속할 때 사용하고 Categorical_Crossentropy 는 각 샘플이 여러개의 class 에 속할수 있을때 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7b36906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 72s 668ms/step - loss: 7.5221 - val_loss: 7.4100\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 56s 653ms/step - loss: 7.3141 - val_loss: 7.2144\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 55s 649ms/step - loss: 7.1439 - val_loss: 7.0553\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 56s 654ms/step - loss: 6.9960 - val_loss: 6.9111\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 55s 645ms/step - loss: 6.8602 - val_loss: 6.7774\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 55s 642ms/step - loss: 6.7336 - val_loss: 6.6518\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 54s 637ms/step - loss: 6.6145 - val_loss: 6.5333\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 54s 634ms/step - loss: 6.5021 - val_loss: 6.4212\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 54s 636ms/step - loss: 6.3956 - val_loss: 6.3146\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 55s 643ms/step - loss: 6.2944 - val_loss: 6.2135\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 6.1984 - val_loss: 6.1173\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 54s 630ms/step - loss: 6.1071 - val_loss: 6.0259\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 53s 628ms/step - loss: 6.0206 - val_loss: 5.9393\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 54s 631ms/step - loss: 5.9388 - val_loss: 5.8576\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 5.8619 - val_loss: 5.7809\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 54s 630ms/step - loss: 5.7899 - val_loss: 5.7092\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 5.7230 - val_loss: 5.6429\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 54s 631ms/step - loss: 5.6614 - val_loss: 5.5817\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 54s 640ms/step - loss: 5.6052 - val_loss: 5.5262\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 54s 639ms/step - loss: 5.5545 - val_loss: 5.4765\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 54s 639ms/step - loss: 5.5095 - val_loss: 5.4325\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 54s 630ms/step - loss: 5.4701 - val_loss: 5.3942\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 55s 642ms/step - loss: 5.4363 - val_loss: 5.3614\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 54s 633ms/step - loss: 5.4078 - val_loss: 5.3339\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3842 - val_loss: 5.3113\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 54s 633ms/step - loss: 5.3652 - val_loss: 5.2929\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3500 - val_loss: 5.2784\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 5.3382 - val_loss: 5.2669\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3291 - val_loss: 5.2581\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 54s 633ms/step - loss: 5.3222 - val_loss: 5.2513\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3172 - val_loss: 5.2463\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 54s 631ms/step - loss: 5.3135 - val_loss: 5.2425\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3108 - val_loss: 5.2397\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 54s 636ms/step - loss: 5.3089 - val_loss: 5.2376\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 54s 636ms/step - loss: 5.3065 - val_loss: 5.2350\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 54s 638ms/step - loss: 5.3059 - val_loss: 5.2341\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 54s 639ms/step - loss: 5.3054 - val_loss: 5.2334\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 54s 637ms/step - loss: 5.3050 - val_loss: 5.2330\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 5.3048 - val_loss: 5.2327\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 54s 640ms/step - loss: 5.3046 - val_loss: 5.2323\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 54s 640ms/step - loss: 5.3045 - val_loss: 5.2322\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 54s 636ms/step - loss: 5.3044 - val_loss: 5.2320\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 54s 641ms/step - loss: 5.3043 - val_loss: 5.2318\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 54s 633ms/step - loss: 5.3042 - val_loss: 5.2317\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 54s 637ms/step - loss: 5.3042 - val_loss: 5.2316\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 54s 635ms/step - loss: 5.3041 - val_loss: 5.2315\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 54s 634ms/step - loss: 5.3041 - val_loss: 5.2315\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 54s 632ms/step - loss: 5.2441 - val_loss: 5.0934\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 54s 636ms/step - loss: 5.1128 - val_loss: 4.9985\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32892a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21b3e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c14fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c6b56d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d6b1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dba0093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')\n",
    "\n",
    "print(type(encoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1731246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : local bjp leader agra booked allegedly sexually harassing police inspector wife victim school teacher also allegedly thrashed accused relatives approached police suffered partial hearing loss arm husband claimed first time accused harassed \n",
      "실제 요약 : bjp leader booked for harassing police wife \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:414 call\n        return self._run_internal_graph(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 2000 but received input with shape (None, 1, 512)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2451416838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"원문 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"실제 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"예측 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13/1739736152.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# stop_condition이 True가 될 때까지 루프 반복\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msampled_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_index_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3459\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3379\u001b[0m           expand_composites=True)\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:414 call\n        return self._run_internal_graph(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 2000 but received input with shape (None, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "# print(encoder_input_test.dtype)\n",
    "# print(type(encoder_input_test))\n",
    "# encoder_input_test1 = encoder_input_test.reshape(-1,)\n",
    "# encoder_input_test2 = np.array(encoder_input_test1, dtype=np.int32) \n",
    "# print(encoder_input_test2.shape)\n",
    "# encoder_input_test.reshape(None,)\n",
    "\n",
    "for i in range(50, 100):\n",
    "     print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "     print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "     print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f244e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdf050ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1832297798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://rare-technologies.com/the_matrix_synopsis.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95fb2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be3d88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1525116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37c51b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbe1fb",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "## ### return_sequences parameter is True일 경우, decoder_outputs 은 배치의 샘플수를 의미한다.\n",
    "### 첫 번째 차원 은 LSTM 레이어에 제공된 배치의 샘플 수를 나타냅니다.두 번째 차원 은 입력 시퀀스 의 시간 단계 수입니다. 두 번째 차원을 인덱싱 하여 주어진 시간 단계 에서 단위의 모든 숨겨진 상태에 액세스 할 수 있습니다.세 번째 차원 은 Keras LSTM 구현에서 units 매개변수에 의해 정의된 출력 공간의 차원입니다 .\n",
    "### 배열의 내용은 LSTM 계층 의 각 시간 단계의 모든 숨겨진 상태입니다 \n",
    "\n",
    "## 라는 점을 새롭게 알게 되었고, LSTM 을 이용하여 어텐션 함수를 이용하는 것이, 정말 좋은 아키텍트라고 느껴졌다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094299e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26258e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799401dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de1f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
